{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import dotenv\n",
    "from crewai import Crew, Agent, Task, tools, Process\n",
    "from crewai.tools import tool\n",
    "from crewai_tools.tools.rag.rag_tool import RagTool\n",
    "from crewai_tools import FileWriterTool\n",
    "from typing import List\n",
    "from langchain_community.chat_models import ChatLiteLLM\n",
    "import litellm\n",
    "# import XDATA\n",
    "from XDATA import create_x_data_collector_task\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"X Tweet Data Collector\")\n",
    "def collect_x_tweets(creators: List[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Collect comprehensive tweet data for specified X (Twitter) creators.\n",
    "\n",
    "    Args:\n",
    "        creators (List[str]): List of X creator usernames to collect tweets from\n",
    "    \n",
    "    Returns:\n",
    "        dict: Structured tweet data with metadata and collected tweets\n",
    "    \"\"\"\n",
    "    return create_x_data_collector_task(creators)\n",
    "\n",
    "class XSentimentAnalysisProject:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the X Sentiment Analysis Project with configurable LLM.\n",
    "        \n",
    "        Args:\n",
    "            model_provider (str): LLM provider (openai, anthropic, etc.)\n",
    "        \"\"\"\n",
    "        # Configure LLM with litellm for flexibility\n",
    "        self.llm = ChatLiteLLM(model=\"gpt-3.5-turbo\",api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    def create_x_data_collector_agent(self):\n",
    "        \"\"\"\n",
    "        Create an agent responsible for collecting X (Twitter) data.\n",
    "    \n",
    "        Returns:\n",
    "            Agent: X Data Collector Agent\n",
    "        \"\"\"\n",
    "        return Agent(\n",
    "            role='X Data Collector',\n",
    "            goal='Retrieve comprehensive tweet data from target X creators',\n",
    "            backstory=\"\"\"You are a sophisticated data gathering expert specialized \n",
    "            in social media content extraction. Your mission is to collect tweets, \n",
    "            analyze their context, and prepare structured data for further analysis.\"\"\",\n",
    "            tools=[\n",
    "                collect_x_tweets\n",
    "            ],\n",
    "            verbose=True,\n",
    "            allow_delegation=False\n",
    "        )\n",
    "    \n",
    "    def create_sentiment_analyzer_agent(self):\n",
    "        \"\"\"\n",
    "        Create an agent for sentiment and contextual analysis of collected tweets.\n",
    "        \n",
    "        Returns:\n",
    "            Agent: Sentiment Analyzer Agent\n",
    "        \"\"\"\n",
    "        return Agent(\n",
    "            role='Social Media Sentiment Analyst',\n",
    "            goal='Perform deep sentiment and thematic analysis on collected tweet data',\n",
    "            backstory=\"\"\"You are an expert in natural language processing and \n",
    "            social media content interpretation. Your advanced analytical skills \n",
    "            help extract nuanced insights from digital communication.\n",
    "            You have access to a rag tool to read information and a text file writing tool to write the results into a text file\"\"\",\n",
    "            tools=[\n",
    "                RagTool(),  # CrewAI's RAG tool for contextual analysis\n",
    "                FileWriterTool()\n",
    "            ],\n",
    "            verbose=True,\n",
    "            allow_delegation=False\n",
    "        )\n",
    "\n",
    "    def create_data_collection_task(self, data_collector_agent, creators):\n",
    "        \"\"\"\n",
    "        Design a task for collecting tweet data from specified creators.\n",
    "    \n",
    "        Args:\n",
    "            data_collector_agent (Agent): X Data Collector Agent\n",
    "            creators (list): List of X creator usernames\n",
    "    \n",
    "        Returns:\n",
    "            Task: Data collection task\n",
    "        \"\"\"\n",
    "        return Task(\n",
    "            description=f\"\"\"Collect tweets from the following X creators: {', '.join(creators)}\n",
    "            - Use XDataScraper in the create_x_data_collector_taskto scrape tweets\n",
    "            - Collect comprehensive tweet metadata including:\n",
    "              * Username\n",
    "              * Tweet content\n",
    "\n",
    "            - Ensure data is stored in a structured JSON format\n",
    "            - Respect data privacy and platform terms of service\"\"\",\n",
    "            agent=data_collector_agent,\n",
    "            output_file='./tweets.json',\n",
    "            expected_output=\"\"\"Comprehensive JSON structure containing:\n",
    "            {\n",
    "                \"data_source\": \"X (Twitter)\",\n",
    "                \"users_analyzed\": [\"username1\", \"username2\"],\n",
    "                \"total_tweets_collected\": 100,\n",
    "                \"tweets\": [\n",
    "                    {\n",
    "                        \"username\": \"creator_username\",\n",
    "                        \"content\": \"Tweet text content\"\n",
    "                    }\n",
    "                ]\n",
    "            }\"\"\"\n",
    "        )\n",
    "\n",
    "    def create_sentiment_analysis_task(self, sentiment_analyzer_agent, collected_data):\n",
    "        \"\"\"\n",
    "        Design a task for sentiment and thematic analysis.\n",
    "        \n",
    "        Args:\n",
    "            sentiment_analyzer_agent (Agent): Sentiment Analyzer Agent\n",
    "            collected_data (dict): JSON data of collected tweets\n",
    "        \n",
    "        Returns:\n",
    "            Task: Sentiment analysis task\n",
    "        \"\"\"\n",
    "        return Task(\n",
    "            description=\"\"\"Perform comprehensive sentiment and thematic analysis on collected tweets\n",
    "            - Analyze sentiment for each tweet (positive, negative, neutral)\n",
    "            - Identify dominant themes and topics across tweets\n",
    "            - Generate a detailed report with insights and save to a text file\n",
    "            - Include visualizations of sentiment distribution\n",
    "            - Provide actionable insights about each creator's content\"\"\",\n",
    "            agent=sentiment_analyzer_agent,\n",
    "            context=[collected_data],\n",
    "            expected_output=\"\"\"text file Report with:\n",
    "            1. Overall sentiment analysis\n",
    "            2. Creator-specific insights\n",
    "            3. Thematic breakdown\n",
    "            4. Engagement metrics visualization\"\"\"\n",
    "        )\n",
    "\n",
    "    def run_analysis(self, creators):\n",
    "        \"\"\"\n",
    "        Execute the complete X sentiment analysis workflow.\n",
    "        \n",
    "        Args:\n",
    "            creators (list): List of X creator usernames\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        # Initialize agents\n",
    "        data_collector = self.create_x_data_collector_agent()\n",
    "        sentiment_analyzer = self.create_sentiment_analyzer_agent()\n",
    "\n",
    "        collected_data = self.create_data_collection_task(\n",
    "            data_collector,\n",
    "            creators\n",
    "        )\n",
    "\n",
    "        # Create sentiment analysis task with the collected data\n",
    "        sentiment_analysis_task = self.create_sentiment_analysis_task(\n",
    "            sentiment_analyzer, \n",
    "            collected_data  # Pass the actual collected data instead of an empty placeholder\n",
    "        )\n",
    "\n",
    "        # Create crew and execute workflow\n",
    "        crew = Crew(\n",
    "            agents=[data_collector,sentiment_analyzer],  # Remove data collector since scraping is now pre-done\n",
    "            tasks=[collected_data,sentiment_analysis_task],\n",
    "            process=Process.sequential,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        # Run the workflow\n",
    "        result = crew.kickoff()\n",
    "        return result\n",
    "\n",
    "def main():\n",
    "    # Example X creators to analyze\n",
    "    x_creators = [\n",
    "        'elonmusk', 'naval', 'paulg', \n",
    "        'sama', 'lex_fridman', 'balajis'\n",
    "    ]\n",
    "\n",
    "    # Initialize and run project\n",
    "    project = XSentimentAnalysisProject()\n",
    "    analysis_results = project.run_analysis(x_creators)\n",
    "    \n",
    "    # Optional: Save or further process results\n",
    "    print(\"Analysis Complete:\", analysis_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
